{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18jbSCblU_-FxPKqkFmtuVPF-_NaeG3wX",
      "authorship_tag": "ABX9TyOS2HWq/nuC/tRxjFDS1IGp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SruthiSub/my-first-pr/blob/main/Implementation_of_Neural_Networks_using_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kERI2arS9HT-"
      },
      "outputs": [],
      "source": [
        "#importing all required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to download file of train data from google drive\n",
        "!gdown 17MjnQcrDmzrdN904aBejisgi1wRM9Kzk\n",
        "#to download file of test data from google drive\n",
        "!gdown 1wRwKiAiDhmDXQTFBn4jZYCYX_kIGvs46"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KK-3I78ARoZ",
        "outputId": "8fbec446-6854-4123-b016-f8d5eafbfe5a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17MjnQcrDmzrdN904aBejisgi1wRM9Kzk\n",
            "To: /content/train.csv\n",
            "100% 2.04M/2.04M [00:00<00:00, 77.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wRwKiAiDhmDXQTFBn4jZYCYX_kIGvs46\n",
            "To: /content/test.csv\n",
            "100% 3.89M/3.89M [00:00<00:00, 133MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to read csv file of train data and split it into Y and X train data\n",
        "TrainDataVerdicts=pd.read_csv(\"/content/train.csv\",usecols=[0])\n",
        "TrainData=pd.read_csv(\"/content/train.csv\",usecols=[1,2,3,4,5,6,7,8,9])\n",
        "#to read csv file of test data and split it into Y and X test data\n",
        "TestDataVerdicts=pd.read_csv(\"/content/test.csv\",usecols=[0])\n",
        "TestData=pd.read_csv(\"/content/test.csv\",usecols=[1,2,3,4,5,6,7,8,9])\n"
      ],
      "metadata": {
        "id": "ntdu59awFARV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "6EcUoNbnJbPx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the neural network\n",
        "model=keras.Sequential()\n",
        "\n",
        "model.add(Dense(units=256,input_shape=[TrainData.shape[1]],activation='relu'))\n",
        "model.add(Dense(units=256,activation='relu'))\n",
        "model.add(Dense(units=128,activation='relu'))\n",
        "model.add(Dense(units=256,activation='relu'))\n",
        "model.add(Dense(units=128,activation='relu'))\n",
        "model.add(Dense(units=128,activation='relu'))\n",
        "model.add(Dense(units=128,activation='relu'))\n",
        "model.add(Dense(units=64,activation='relu'))\n",
        "model.add(Dense(units=64,activation='relu'))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',loss='mae')\n",
        "losses=model.fit(TrainData,TrainDataVerdicts,validation_data=(TestData,TestDataVerdicts),batch_size=150,epochs=20)\n",
        "#epochs is the number of times we go through the training set. Notice that each time we run it, the error decreases. So the higher the epochs, the more the accuracy of our prediction. Yet, we should ensure an optimum value of epoc \n",
        "#batchsize tells us how many rows we are proccessing at a time.\n"
      ],
      "metadata": {
        "id": "Y3l2U34xJ8dl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2af48a1-6cf2-479b-c55e-056188812eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_26 (Dense)            (None, 256)               2560      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,673\n",
            "Trainable params: 212,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "219/219 [==============================] - 8s 25ms/step - loss: 77.0719 - val_loss: 29462.9707\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 5s 24ms/step - loss: 2.4886 - val_loss: 29459.7910\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 1.0471 - val_loss: 29460.6660\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.6566 - val_loss: 29459.6660\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 5s 24ms/step - loss: 0.6042 - val_loss: 29459.5098\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.6379 - val_loss: 29460.0254\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.4714 - val_loss: 29460.5293\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 5s 25ms/step - loss: 0.3503 - val_loss: 29459.9707\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 1.4551 - val_loss: 29460.1504\n",
            "Epoch 10/20\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.2107"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pred=model.predict(TestData)\n",
        "print(Pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMobrqD8bv-1",
        "outputId": "378e069c-0217-4223-f565-9f23df5e5bba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1842/1842 [==============================] - 6s 3ms/step\n",
            "[[0.9973948 ]\n",
            " [0.9973948 ]\n",
            " [0.9973948 ]\n",
            " ...\n",
            " [0.99739486]\n",
            " [0.99739486]\n",
            " [0.99739486]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in Pred:\n",
        "  if i>0.5:\n",
        "    i=1\n",
        "  else:\n",
        "    i=0\n",
        "  "
      ],
      "metadata": {
        "id": "DfglGbGS7A0K",
        "outputId": "399c272c-5308-4122-c792-061d7ccf1abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n",
            "H\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=np.array(Pred)\n",
        "df=pd.DataFrame(prediction)\n",
        "df.to_csv(\"submission.csv\")\n"
      ],
      "metadata": {
        "id": "ek-62chrJQTe"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}